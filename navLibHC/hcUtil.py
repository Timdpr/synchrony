"""
bunch of helpful functions
CK 2014
"""
import numpy as np
from matplotlib import pyplot as plt
from sys import stdout
import hcPlotting

def slug(s):
    replacements = [('.','_'), (',','_'), (' ','_'), ('^',''), ('$',''), ('{', ''), ('}', ''), ('=', '_')]
    for a,b in replacements:
        s = s.replace(a,b)
    return s

def printprogress(msg,n,of):
    stdout.write("\r\033[2K%s %d of %d (%d%%)" %(msg,n,of,n*100/of))
    stdout.flush()


def centerdot(M,N):
    inputc = np.zeros((M,N))
    inputc[M/2-1,N/2-1] = 1
    inputc[M/2,N/2-1] = 1
    inputc[M/2-1,N/2] = 1
    inputc[M/2,N/2] = 1
    #inputc = inputc*2-1
    return M,N,inputc


def horzline(M,N):
    inputc = np.zeros((M,N))
    for j in range(N):
        inputc[M/2-1,j] = 1
        #inputc[M/2,j] = 1
    #inputc = inputc*2-1
    return M,N,inputc


def cornerdots(M,N,where,margin=2):
    inputc = np.zeros((M,N))
    sz = 2 # size of dot
    for w in where:
        pos = None
        if w == "tl":
            pos = (margin,margin)
        if w == "tr":
            pos = (margin,N-margin-sz)
        if w == "bl":
            pos = (M-margin-sz,margin)
        if w == "br":
            pos = (M-margin-sz,N-margin-sz)

        inputc[pos[0],   pos[1]  ] = 1
        inputc[pos[0]+1, pos[1]  ] = 1
        inputc[pos[0],   pos[1]+1] = 1
        inputc[pos[0]+1, pos[1]+1] = 1
    return M,N,inputc




def idxtoimg(M,N,nodelist):
    img = np.zeros((M,N))
    coords = np.array(zip(*nodelist))
    img[coords[0],coords[1]] = 1
    return img




class naivebayes:
    """
    repeated gaussian naive bayes for growing window increments.

    assumes in each condition & at each window increment step, measured values from different
    trials i are iid following a normal distribution: N(x_i|mu_(class,step) , var_(class,step)).
    this distribution is first estimated by MLE, so for each step & condition, its parameters
    are the sample mean and variance of (a training subset of) the measured values from that condition
    at that step. This happens at initialisation.
    These estimated densities are used as likelihood functions for each window step and for
    each class, which yields posterior probabilities of each condition, at each step & for each trial.

    """
    def __init__(self,experiments,measurename,train_trials=None,plotmodels=False):
        """
        Args:
            experiments: List of two experiments - each experiment treated as one class.
            measurename: Name of the growing window measure from which to get values.
            train_trials: List of indices of trials to use to estimate parameters.
                          If None, use all trials.
            plotmodels: Plot the likelihood function for each class.
        """
        self.experiments = experiments
        self.measurename = measurename
        self.classes = [e.name for e in experiments]
        assert len(set(self.classes)) == len(self.classes) # experiments should have different names
        assert len(self.classes) == 2 # plotting code down below can't deal with multiple classes.
        self.means = {}
        self.varcs = {}
        self.likelihoods = {}
        self.model = {}
        self.normpdf = lambda x,m,v: np.exp(-((x-m)**2)/(2.0*v)) / np.sqrt(2*np.pi*v)
        # MLE estimation:
        for e in experiments:
            C = e.name
            results = np.array(e.getresults(measurename))
            # self.measurements[C] = results # assumed to be of shape trials x time
            if not train_trials:
                train_trials = range(results.shape[0])
            self.means[C] = np.mean(results[train_trials,:],axis=0) # the sample mean at each step
            self.varcs[C] =  np.var(results[train_trials,:],axis=0) # the sample var at each step

            if plotmodels:
                self.model[C] = np.zeros((400,results.shape[1]))
                for step in range(results.shape[1]):
                    self.model[C][:,step] = self.normpdf(np.arange(0, 1, 0.0025),
                                                         self.means[C][step], self.varcs[C][step])
                    plt.figure()
                    plt.imshow(model[C],interpolation='nearest',origin='lower',aspect='auto',cmap='bone')
                    plt.colorbar()
                    plt.title(C)

    def posteriors(self,experiment):
        """
        For each trial in the given experiment, return the posterior probabilities that it
        belongs to each of the conditions used in training the classifier.

        The likelihood that the result in trial i at time t was generated by experiment C is
        L(r_(i,t)|C,t) = N(r_(i,t)|mu_C(t),var_C(t))

        Thus the posterior probability of class C given the result in trial i at time t is
        P(C|r_(i,t),t) = L(r_(i,t)|C,t)*P(C) / sum_classes(L(r_(i,t)|c_i,t)P(c_i))

        Arg:
            experiment object

        Returns:
            dict p, whose keys C are all the classes used in training the classifier,
            and where p[C] is a (trials x steps) array of probabilities that at step s,
            trial i of the given experiment belong to class C.
        """
        # so the likelihood that the result in trial i at time t was generated by experiment C is
        # L(r_(i,t)|C,t) = normpdf(r_(i,t),mean_C(t),var_C(t))
        # So we evaluate a probability _density_ at particular _points_... permissible, since a
        # constant scaling factor of L disappears in the normalization involved in calculating posteriors.
        results = np.array(experiment.getresults(self.measurename))
        likelihoods = {}
        for C in self.classes:
            likelihoods[C] = np.zeros(results.shape)
            for step in range(results.shape[1]):
                likelihoods[C][:,step] = self.normpdf(results[:, step],
                                                      self.means[C][step], self.varcs[C][step])
        # Thus the posterior probability of class C given the result in trial i at time t is
        # P(C|r_(i,t),t) = L(r_(i,t)|C,t)*P(C) / sum_classes(L(r_(i,t)|c_i,t)P(c_i))
        posteriors = {}
        prior_c = 1.0/len(self.classes) # assume flat prior over classes
        for C in self.classes:
            posteriors[C] = np.zeros(results.shape)
            for step in range(results.shape[1]):
                normalize = np.sum([likelihoods[ci][:,step] * prior_c for ci in self.classes], axis=0)
                posteriors[C][:,step] = likelihoods[C][:,step] * prior_c / normalize
        return posteriors

    def plot_posteriors(self,C=None):
        if not C:
            C = self.classes[0]
        postrs = [self.posteriors(e)[C] for e in self.experiments]
        plt.figure(figsize=hcPlotting.fig_size)
        plt.imshow(np.vstack(postrs),cmap='RdBu',interpolation='nearest',aspect='auto')
        plt.xticks([],[])
        plt.xlabel("simulation time step")
        plt.ylabel("trial")
        plt.colorbar()
        plt.title("posterior of class "+C+" for trials from classes "+", ".join(self.classes))


    def classification_MAP(self):
        """
        Classify each trial from each experiment at each time, by argmax_C P(C|r_(i,t),t).

        Returns:
            dict of arrays
        """
        classification = {}
        for e in self.experiments:
            pstrs = np.dstack([self.posteriors(e)[c] for c in self.classes])
            classification[e.name] = np.array(self.classes)[np.argmax(pstrs,axis=2)]
        return classification

    def evaluation(self,C=None,doplot=True):
        """ Return the evolution of true classifications as C vs. false classifications as C """
        assert len(self.classes) == 2
        if not C:
            C = self.classes[0]
        assert C in self.classes
        clss = self.classification_MAP()
        for e in self.experiments:
            if e.name == C:
                tp = clss[e.name] == C
            else:
                fp = clss[e.name] == C

        if doplot:
            plt.figure(figsize=hcPlotting.fig_size)
            plt.plot(np.mean(tp, axis=0),color='g',label='TP')
            plt.plot(np.mean(fp,axis=0),color='r',label='FP')
            plt.xlabel("time")
            #plt.legend(loc=5)
            plt.title("correct/incorrect classification")
        return tp,fp

    def time_to_correct_decision(self,experiment=None,thr=0.5,stay_above=True,unit="spikes",spikemeasure="growing_spikecount"):
        """ time until posterior for the correct class either stays above threshold or first crosses it"""
        assert len(self.classes) == 2
        if not experiment:
            experiment = self.experiments[0]
        pstrs = self.posteriors(experiment)[experiment.name] # posteriors for the experiment's true class
        nr_trials,nr_steps = pstrs.shape

        nr_spikes_fired = experiment.getresults(spikemeasure)
        assert len(nr_spikes_fired) == nr_trials
        assert np.all([len(nr_spikes_fired[i]) == nr_steps for i in range(nr_trials)])

        # either go backwards and take note when posterior drops below threshold,
        # (..and if it never drops below threshold, note a decision at the first window)
        # or go forwards and take note when it goes above.
        decisiontimes = np.empty(nr_trials)
        decisiontimes[:] = np.Inf
        if stay_above:
            for tr in range(nr_trials):
                if pstrs[tr,nr_steps-1]<thr:
                    # no sense in looking when it drops below threshold when it never reaches it
                    pass
                else:
                    for s in range(nr_steps-1,-1,-1):
                        if s == 0 or (pstrs[tr,s-1] < thr):
                            decisiontimes[tr] = nr_spikes_fired[tr][s] if unit=="spikes" else s*unit
                            break
        else:
            for tr in range(nr_trials):
                for s in range(nr_steps):
                    if pstrs[tr,s] > thr:
                        decisiontimes[tr] = nr_spikes_fired[tr][s] if unit=="spikes" else s*unit
                        break
        return decisiontimes

    def plot_all_times_to_correct_decision(self,thr=0.5,stay_above=True,unit="spikes",spikemeasure="growing_spikecount", do_title=True):
        times = np.array([self.time_to_correct_decision(e,thr,stay_above,unit,spikemeasure) for e in self.experiments]).flatten()
        # times[30:50] = np.Inf
        maximum = int(np.ceil(max(times[times!=np.Inf])))
        plt_inf = maximum+2 # for unsuccessful trials (time=Inf), set time to some value distinct from any actual decision time.
        times[times==np.Inf] = plt_inf

        fig = plt.figure(figsize=(hcPlotting.fig_width,hcPlotting.fig_height/3))

        bins = np.hstack([np.arange(0.25,maximum+1,0.5),[plt_inf,plt_inf+1]])
        n,_,_ = plt.hist(times,bins,color='k',edgecolor='w')

        ax = plt.gca()
        ax.set_xlim((0,plt_inf+1))
        ax.set_ylim(ax.get_ylim()[0],ax.get_ylim()[1]+1)
        plt.plot((plt_inf,plt_inf),(0,ax.get_ylim()[1]),'r')

        ax.set_xticks(range(maximum+1)+[plt_inf+0.5])
        ax.set_xticklabels([str(i) for i in range(maximum+1)]+[r'$\infty$'])

        ax.set_ylabel("nr. of trials")
        ax.set_xlabel("spikes observed before classification")
        if do_title:
            plt.title("thr = "+str(thr)+", stay_above = "+str(stay_above)+", classes: " +" vs. ".join(self.classes))